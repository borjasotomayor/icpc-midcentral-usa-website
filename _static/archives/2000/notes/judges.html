<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML><HEAD><TITLE>Notes to Judges</TITLE></HEAD>
<BODY>

<H1 ALIGN=CENTER>Notes to Judges</H1>

<P>Read the <A HREF="errors.html">Error Messages</A>,
<A HREF="teams.html">Notes to Teams</A>, and
<A HREF="sites.html">Notes to Sites</A> right now. 
...  Done?  OK.

<P>The judges' diskette contains one subdirectory for each problem, which
includes the description in HTML, the source file, the input and output files,
and either an executable program or Java bytecode files. It contains a
subdirectory called <TT>NOTES</TT> that includes the HTML source for these
notes. It also contains a subdirectory called <TT>JUDGE</TT> that includes
enhanced versions of the judging utilities used in the last two contests. If
you do not already have a tried-and-true method for judging, you might want to
take a look at them. Instructions are provided in <A HREF="util.html">Using
the Judging Utilities</A>, and are available in text form in the
<TT>read.me</TT> file.

<P>All the textual information on the judges' disk can be viewed through
a Web browser by accessing <tt>browse.html</tt> in the <tt>mcpc2000</tt>
directory installed by the judging utilities (or in the root of the judges'
diskette).

<P>Regardless of what judging method you use, remember the following
(the included utilities take care of these details for you):

<UL>
<LI>If a program is correct, the team's output file will match the correct
output file <EM>exactly</EM>.  If the match is not exact, you will have to do a visual
inspection to tell whether the problem is a wrong answer or a presentation
error.</LI>
<LI>Remove a team's diskette or write-protect it before judging to ensure
that nothing is written to it.</LI>
<LI>Always copy a fresh set of correct input and output files before
judging a run, because teams' programs have been known to trash files.</LI>
</UL>

<P>As in recent contests,
<UL>
<LI>problem solutions are unique and must
be formatted exactly, so output can be judged using a file comparison utility,</LI>
<LI>all problems are judged with one test file (which of course will
include multiple test cases), and</LI>
<LI>all input files have sentinels that
signal the end of the input, so it is not necessary for teams to detect
end-of-file. (End-of-file handling differs between languages and sometimes
between different compilers for the same language. It can cause problems for
teams using tools that they're not used to.)</LI>
</UL>

<P>We think the easiest problems are <I>Easier Done than Said?</I> and
<I>Colorville</I>, followed by <I>Instruens Fabulam</I> and
<I>The Triangle Game</I>, and then <I>Falling Leaves</I> and
<I>Edge Detection</I>.
We don't expect many teams to solve all six problems but most teams should
solve one or two.

<P>Andy (the toolsmith) wrote <I>The Triangle Game</I>, 
and <I>Falling Leaves</I>. 
Eric (the webmaster) wrote <I>Easier Done than Said?</I> and
<I>Instruens Fabulam</I>.  I wrote <I>Colorville</I> and <I>Edge Detection</I>
(with Andy providing the solution for the latter).

<P>Eric will be your regional contact during the contest.  If you have any
questions or corrections you can send him email at 
<A HREF="mailto://EricShade@smsu.edu">EricShade@smsu.edu</A>, or if it's an
emergency you can phone him at 417-836-4944.  Also check the Updates section
of the web site periodically; if any files need to be changed, corrections
will be posted there.

<P><HR>
<ADDRESS>
John Cigas <BR>
Regional Chief Judge: Editor <BR>
Rockhurst University
</ADDRESS>
</BODY></HTML>
